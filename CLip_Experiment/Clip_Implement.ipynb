{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqNJsBk2SD5uQTPMRYe31y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaveyBae/exist2025/blob/main/Clip_Implement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xNgWEd-_EaW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6538ce3b",
        "outputId": "808154d2-c461-4b00-cc2e-f49519a61bf5"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "img_paths = [\n",
        "    (\"dog.jpg\", \"https://images.unsplash.com/photo-1547494912-c69d3ad40e7f?ixlib=rb-4.1.0&q=85&fm=jpg&crop=entropy&cs=srgb&w=640\"),\n",
        "    (\"cat.jpg\", \"https://images.unsplash.com/photo-1518791841217-8f162f1e1131?ixlib=rb-4.0.3&w=640&q=80\"),\n",
        "    (\"beach.jpg\", \"https://images.unsplash.com/photo-1507525428034-b723cf961d3e?ixlib=rb-4.0.3&w=640&q=80\"),\n",
        "]\n",
        "\n",
        "for filename, url in img_paths:\n",
        "    r = requests.get(url)\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(r.content)\n",
        "    print(f\"‚úÖ Saved {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGg7yZu5EtZ8",
        "outputId": "cc6a9427-2a2a-4c01-8f49-feebd97fca44"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved dog.jpg\n",
            "‚úÖ Saved cat.jpg\n",
            "‚úÖ Saved beach.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c82afc91",
        "outputId": "e50f272f-5872-4611-801c-aedf447a04bf"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Load models\n",
        "img_model = SentenceTransformer('clip-ViT-B-32')\n",
        "text_model = SentenceTransformer('sentence-transformers/clip-ViT-B-32-multilingual-v1')\n",
        "\n",
        "# --- Ensure you have the full paths to your files ---\n",
        "try:\n",
        "    img_paths = [\"/content/dog.jpg\", \"/content/cat.jpg\", \"/content/beach.jpg\"]\n",
        "    images = [Image.open(p).convert(\"RGB\") for p in img_paths]\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Please ensure the image files are uploaded and the paths above are correct!\")\n",
        "    images = []\n",
        "\n",
        "if images:\n",
        "    # --- Encode images and text ---\n",
        "    img_embeddings = img_model.encode(images, convert_to_tensor=True, normalize_embeddings=True)\n",
        "\n",
        "    texts = [\n",
        "        \"A dog in the snow\",      # English\n",
        "        \"Eine Katze\",             # German: A cat\n",
        "        \"Una playa con palmeras.\" # Spanish: A beach with palm trees\n",
        "    ]\n",
        "    text_embeddings = text_model.encode(texts, convert_to_tensor=True, normalize_embeddings=True)\n",
        "\n",
        "    # --- New section: Output semantic vectors ---\n",
        "    print(\"--- Semantic Vector Output ---\")\n",
        "\n",
        "    # Print Image Embeddings\n",
        "    print(\"\\nüñºÔ∏è  Image Embeddings:\")\n",
        "    print(f\"Shape: {img_embeddings.shape}\")\n",
        "    print(img_embeddings)\n",
        "\n",
        "    # Print Text Embeddings\n",
        "    print(\"\\nüìù Text Embeddings:\")\n",
        "    print(f\"Shape: {text_embeddings.shape}\")\n",
        "    print(text_embeddings)\n",
        "\n",
        "    print(\"\\n--- Similarity Matching Results ---\")\n",
        "    # --- Original code continues ---\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    cos_sim = util.cos_sim(text_embeddings, img_embeddings)\n",
        "\n",
        "    # Print results\n",
        "    for text, scores in zip(texts, cos_sim):\n",
        "        max_idx = torch.argmax(scores)\n",
        "        print(f\"\\nüìù Text: {text}\")\n",
        "        print(f\"üìà Best match score: {scores[max_idx]:.4f}\")\n",
        "        print(f\"üñºÔ∏è  Matched image: {img_paths[max_idx]}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Semantic Vector Output ---\n",
            "\n",
            "üñºÔ∏è  Image Embeddings:\n",
            "Shape: torch.Size([3, 512])\n",
            "tensor([[ 0.0292,  0.0259, -0.0095,  ..., -0.0249, -0.0065,  0.0040],\n",
            "        [-0.0188,  0.0002,  0.0189,  ...,  0.0100,  0.0011, -0.0014],\n",
            "        [ 0.0051,  0.0061, -0.0170,  ...,  0.0406,  0.0036, -0.0241]])\n",
            "\n",
            "üìù Text Embeddings:\n",
            "Shape: torch.Size([3, 512])\n",
            "tensor([[-6.4259e-05,  1.0246e-02, -2.9634e-02,  ..., -1.0483e-02,\n",
            "          4.3085e-03, -7.4803e-02],\n",
            "        [ 9.0206e-03, -9.9677e-03, -1.3959e-02,  ..., -3.5666e-02,\n",
            "         -4.1808e-02,  3.4178e-03],\n",
            "        [ 8.9918e-03,  4.3758e-02,  7.3397e-03,  ...,  3.5206e-02,\n",
            "         -3.9791e-02,  3.1345e-02]])\n",
            "\n",
            "--- Similarity Matching Results ---\n",
            "\n",
            "üìù Text: A dog in the snow\n",
            "üìà Best match score: 0.3132\n",
            "üñºÔ∏è  Matched image: /content/dog.jpg\n",
            "\n",
            "üìù Text: Eine Katze\n",
            "üìà Best match score: 0.2582\n",
            "üñºÔ∏è  Matched image: /content/cat.jpg\n",
            "\n",
            "üìù Text: Una playa con palmeras.\n",
            "üìà Best match score: 0.2690\n",
            "üñºÔ∏è  Matched image: /content/beach.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# 1. Load the model\n",
        "model = SentenceTransformer('clip-ViT-B-32')\n",
        "\n",
        "# 2. Define the image paths and categories\n",
        "image_paths = [\"dog.jpg\", \"cat.jpg\", \"beach.jpg\"] # Changed to a list of image paths\n",
        "categories = [\"a photo of a dog\", \"a photo of a cat\", \"a photo of a car\", \"a photo of a bird\" , \"a photo of a beach\"]\n",
        "\n",
        "# Process each image\n",
        "for image_path in image_paths: # Loop through each image path\n",
        "    # Load the image\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image not found at path '{image_path}'.\")\n",
        "        image = None\n",
        "\n",
        "    if image:\n",
        "        # 3. Encode\n",
        "        image_embedding = model.encode(image, convert_to_tensor=True)\n",
        "        text_embeddings = model.encode(categories, convert_to_tensor=True)\n",
        "\n",
        "        # 4. Compute cosine similarity\n",
        "        cosine_scores = util.cos_sim(image_embedding, text_embeddings)\n",
        "\n",
        "        # --- Key modification here ---\n",
        "        # 5. Before Softmax, add a scaling factor to amplify score differences\n",
        "        scaling_factor = 50  # You can try different values, e.g., 20 or 100\n",
        "        scaled_scores = cosine_scores[0] * scaling_factor\n",
        "\n",
        "        # Apply Softmax to the scaled scores\n",
        "        probs = torch.nn.functional.softmax(scaled_scores, dim=0)\n",
        "        # --- End of modification ---\n",
        "\n",
        "        # Print probabilities for each category\n",
        "        print(f\"--- Classification Results for Image '{image_path}' (Scaled) ---\")\n",
        "        for i, category in enumerate(categories):\n",
        "            print(f\"Category: '{category}', Probability: {probs[i].item():.4f}\")\n",
        "\n",
        "        # Find the category with the highest probability\n",
        "        best_category_idx = torch.argmax(probs).item()\n",
        "        best_category = categories[best_category_idx]\n",
        "\n",
        "        print(f\"\\n‚úÖ Final Prediction: This is most likely a photo of '{best_category}'.\")\n",
        "    print(\"-\" * 30) # Separator for clarity between images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5mGMJznQ04H",
        "outputId": "196d88f8-337c-44fe-d742-339b5fd6e661"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Classification Results for Image 'dog.jpg' (Scaled) ---\n",
            "Category: 'a photo of a dog', Probability: 0.9140\n",
            "Category: 'a photo of a cat', Probability: 0.0359\n",
            "Category: 'a photo of a car', Probability: 0.0104\n",
            "Category: 'a photo of a bird', Probability: 0.0278\n",
            "Category: 'a photo of a beach', Probability: 0.0119\n",
            "\n",
            "‚úÖ Final Prediction: This is most likely a photo of 'a photo of a dog'.\n",
            "------------------------------\n",
            "--- Classification Results for Image 'cat.jpg' (Scaled) ---\n",
            "Category: 'a photo of a dog', Probability: 0.0720\n",
            "Category: 'a photo of a cat', Probability: 0.8963\n",
            "Category: 'a photo of a car', Probability: 0.0078\n",
            "Category: 'a photo of a bird', Probability: 0.0205\n",
            "Category: 'a photo of a beach', Probability: 0.0034\n",
            "\n",
            "‚úÖ Final Prediction: This is most likely a photo of 'a photo of a cat'.\n",
            "------------------------------\n",
            "--- Classification Results for Image 'beach.jpg' (Scaled) ---\n",
            "Category: 'a photo of a dog', Probability: 0.0128\n",
            "Category: 'a photo of a cat', Probability: 0.0107\n",
            "Category: 'a photo of a car', Probability: 0.0100\n",
            "Category: 'a photo of a bird', Probability: 0.0215\n",
            "Category: 'a photo of a beach', Probability: 0.9450\n",
            "\n",
            "‚úÖ Final Prediction: This is most likely a photo of 'a photo of a beach'.\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}