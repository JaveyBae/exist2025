{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1gfGNrwzCF2XQN1uueU1q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaveyBae/exist2025/blob/main/Experiment_onTweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Id42w_neguv",
        "outputId": "c18fa279-7418-479a-8471-ccf518fcb1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentence-transformers torch\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "from torch.nn.functional import softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model Loading ---\n",
        "# We will load a RoBERTa model for masked language modeling.\n",
        "# In a real application, you would fine-tune this on a relevant task if needed.\n",
        "roberta_model_name = 'roberta-base'\n",
        "# Use the AutoTokenizer to automatically get the correct tokenizer for the model\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "# Load the RoBERTa tokenizer\n",
        "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_model_name)\n",
        "# Load a RoBERTa model with a masked language model head\n",
        "roberta_model_mlm = AutoModelForMaskedLM.from_pretrained(roberta_model_name)\n",
        "\n",
        "# --- CLIP Model Loading ---\n",
        "# Using the sentence-transformers library to easily load the text encoder part of CLIP\n",
        "clip_model_name = 'clip-ViT-B-32'\n",
        "clip_model = SentenceTransformer(clip_model_name)\n",
        "\n",
        "print(\"模型加载成功!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLKSlsSqflnS",
        "outputId": "1512487e-8112-4c8d-f45a-c380ae42d568"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型加载成功!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "6aCu8uBsgwYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example texts\n",
        "texts = [\n",
        "    \"Women belong in the kitchen.\",  # Obvious sexism\n",
        "    \"He is too emotional to be a leader, just like a woman.\", # Implicit sexism\n",
        "    \"The new software update will be released tomorrow.\", # Neutral\n",
        "    \"She was promoted because of her skills and hard work.\", # Neutral\n",
        "    \"Girls are not good at math.\", # Sexist\n",
        "    \"This is a great achievement for all the scientists involved.\" # Neutral\n",
        "    \"one time I sucked d**k so hard that I looked at myself in the mirror and was like holy shiiit I’m so ugly &amp; he was like “you look like a whore. I love it!” LMAOOOOO\" # Discriminatory\n",
        "\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "eemLWnh5fpFv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddf63cda"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2f22d9b",
        "outputId": "ec196bcb-0ed0-4207-8cd4-0dd7f41bf61b"
      },
      "source": [
        "def classify_with_roberta_prompting(text, tokenizer, model, prompt_template):\n",
        "    \"\"\"\n",
        "    Classify using prompt and RoBERTa MASK prediction.\n",
        "\n",
        "    Args:\n",
        "        text (str): The original text to classify.\n",
        "        tokenizer: RoBERTa tokenizer.\n",
        "        model: RoBERTa Masked Language Model.\n",
        "        prompt_template (str): Prompt template containing <mask>, e.g., \"This statement is <mask>.\"\n",
        "\n",
        "    Returns:\n",
        "        tuple: List of predicted words and their corresponding scores.\n",
        "    \"\"\"\n",
        "    # RoBERTa uses <mask> instead of [MASK]\n",
        "    prompt_text = prompt_template.replace(\"[MASK]\", \"<mask>\").replace(\"[TEXT]\", text)\n",
        "\n",
        "    # Combine the text and prompt\n",
        "    # RoBERTa doesn't use special tokens like [CLS] and [SEP] in the same way as BERT\n",
        "    # We can just concatenate the text and the prompt\n",
        "    input_text = f\"{text} {prompt_text}\"\n",
        "\n",
        "    # Find the <mask> token id\n",
        "    mask_token_id = tokenizer.mask_token_id\n",
        "\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Get the position of the <mask> token in the input sequence\n",
        "    mask_token_index = torch.where(inputs[\"input_ids\"] == mask_token_id)[1]\n",
        "\n",
        "    if len(mask_token_index) == 0:\n",
        "        print(\"Error: <mask> token not found in the input.\")\n",
        "        return None, None\n",
        "\n",
        "    # Perform prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = outputs.logits\n",
        "\n",
        "    # Get the prediction results for the <mask> position\n",
        "    mask_token_logits = predictions[0, mask_token_index, :]\n",
        "\n",
        "    # Apply softmax to convert logits to probabilities\n",
        "    mask_token_probabilities = softmax(mask_token_logits, dim=-1)\n",
        "\n",
        "    # Get the top N predicted words and their probabilities\n",
        "    top_n = 5\n",
        "    top_probabilities, top_indices = torch.topk(mask_token_probabilities, top_n, dim=-1)\n",
        "\n",
        "    predicted_tokens = [tokenizer.decode([token_id]) for token_id in top_indices[0]]\n",
        "    predicted_scores = top_probabilities[0].tolist()\n",
        "\n",
        "    return predicted_tokens, predicted_scores\n",
        "\n",
        "# Define the prompt template\n",
        "# Note: We use [TEXT] as a placeholder which will be replaced by the actual text in the function\n",
        "prompt_template = \"This statement is [MASK].\"\n",
        "\n",
        "# Example texts (using the previously defined texts list)\n",
        "# texts = [\n",
        "#     \"Women belong in the kitchen.\",  # Obvious sexism\n",
        "#     \"He is too emotional to be a leader, just like a woman.\", # Implicit sexism\n",
        "#     \"The new software update will be released tomorrow.\", # Neutral\n",
        "#     \"She was promoted because of her skills and hard work.\", # Neutral\n",
        "#     \"Girls are not good at math.\", # Sexist\n",
        "#     \"This is a great achievement for all the scientists involved.\" # Neutral\n",
        "# ]\n",
        "\n",
        "\n",
        "print(\"--- RoBERTa Prompting Prediction Results ---\")\n",
        "for text in texts:\n",
        "    predicted_tokens, predicted_scores = classify_with_roberta_prompting(\n",
        "        text, roberta_tokenizer, roberta_model_mlm, prompt_template\n",
        "    )\n",
        "\n",
        "    print(f\"Text: '{text}'\")\n",
        "    if predicted_tokens:\n",
        "        print(\"Predicted words to fill <mask> and their probabilities:\")\n",
        "        for token, score in zip(predicted_tokens, predicted_scores):\n",
        "            print(f\"  - {token}: {score:.4f}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "print(\"\\nNote: The RoBERTa model was pre-trained on a massive dataset and has good ability to fill <mask>. By observing the words it predicts, we can indirectly infer the attributes of the original text (e.g., whether it's sexist). However, this method's results are more interpretive and may require manual analysis of the predicted words to draw final conclusions.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RoBERTa Prompting Prediction Results ---\n",
            "Text: 'Women belong in the kitchen.'\n",
            "Predicted words to fill <mask> and their probabilities:\n",
            "  -  false: 0.1893\n",
            "  -  unacceptable: 0.0892\n",
            "  -  wrong: 0.0879\n",
            "  -  incorrect: 0.0523\n",
            "  -  sexist: 0.0450\n",
            "--------------------\n",
            "Text: 'He is too emotional to be a leader, just like a woman.'\n",
            "Predicted words to fill <mask> and their probabilities:\n",
            "  -  unacceptable: 0.0891\n",
            "  -  disturbing: 0.0554\n",
            "  -  false: 0.0484\n",
            "  -  wrong: 0.0412\n",
            "  -  true: 0.0334\n",
            "--------------------\n",
            "Text: 'The new software update will be released tomorrow.'\n",
            "Predicted words to fill <mask> and their probabilities:\n",
            "  -  below: 0.1053\n",
            "  -  final: 0.0969\n",
            "  -  incomplete: 0.0414\n",
            "  -  preliminary: 0.0413\n",
            "  -  official: 0.0387\n",
            "--------------------\n",
            "Text: 'She was promoted because of her skills and hard work.'\n",
            "Predicted words to fill <mask> and their probabilities:\n",
            "  -  false: 0.4298\n",
            "  -  misleading: 0.0923\n",
            "  -  incorrect: 0.0884\n",
            "  -  inaccurate: 0.0451\n",
            "  -  true: 0.0381\n",
            "--------------------\n",
            "Text: 'Girls are not good at math.'\n",
            "Predicted words to fill <mask> and their probabilities:\n",
            "  -  false: 0.1695\n",
            "  -  true: 0.1102\n",
            "  -  untrue: 0.0515\n",
            "  -  misleading: 0.0483\n",
            "  -  nonsense: 0.0418\n",
            "--------------------\n",
            "Text: 'This is a great achievement for all the scientists involved.one time I sucked d**k so hard that I looked at myself in the mirror and was like holy shiiit I’m so ugly &amp; he was like “you look like a whore. I love it!” LMAOOOOO'\n",
            "Predicted words to fill <mask> and their probabilities:\n",
            "  -  amazing: 0.0882\n",
            "  -  priceless: 0.0776\n",
            "  -  true: 0.0656\n",
            "  -  awesome: 0.0550\n",
            "  -  incredible: 0.0365\n",
            "--------------------\n",
            "\n",
            "Note: The RoBERTa model was pre-trained on a massive dataset and has good ability to fill <mask>. By observing the words it predicts, we can indirectly infer the attributes of the original text (e.g., whether it's sexist). However, this method's results are more interpretive and may require manual analysis of the predicted words to draw final conclusions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_with_bert(text_list):\n",
        "    \"\"\"Classify a list of texts using the BERT model\"\"\"\n",
        "    inputs = bert_tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probabilities = softmax(logits, dim=1)\n",
        "        predictions = torch.argmax(probabilities, dim=1)\n",
        "    return predictions, probabilities\n",
        "\n",
        "# Run BERT classification\n",
        "bert_predictions, bert_probabilities = classify_with_bert(texts)\n",
        "\n",
        "print(\"--- BERT Classification Results ---\")\n",
        "for i, text in enumerate(texts):\n",
        "    label = \"Sexist\" if bert_predictions[i].item() == 1 else \"Non-sexist\"\n",
        "    print(f\"Text: '{text}'\\nPrediction: {label} (Confidence: {bert_probabilities[i][bert_predictions[i]].item():.4f})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IbNHHBgfqqk",
        "outputId": "d0437e55-a814-40eb-a578-f0df15b4e0a4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- BERT Classification Results ---\n",
            "Text: 'Women belong in the kitchen.'\n",
            "Prediction: Non-sexist (Confidence: 0.5107)\n",
            "\n",
            "Text: 'He is too emotional to be a leader, just like a woman.'\n",
            "Prediction: Non-sexist (Confidence: 0.5264)\n",
            "\n",
            "Text: 'The new software update will be released tomorrow.'\n",
            "Prediction: Non-sexist (Confidence: 0.5031)\n",
            "\n",
            "Text: 'She was promoted because of her skills and hard work.'\n",
            "Prediction: Non-sexist (Confidence: 0.5437)\n",
            "\n",
            "Text: 'Girls are not good at math.'\n",
            "Prediction: Non-sexist (Confidence: 0.5261)\n",
            "\n",
            "Text: 'This is a great achievement for all the scientists involved.one time I sucked d**k so hard that I looked at myself in the mirror and was like holy shiiit I’m so ugly &amp; he was like “you look like a whore. I love it!” LMAOOOOO'\n",
            "Prediction: Non-sexist (Confidence: 0.5092)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_with_clip(text_list, concept_labels):\n",
        "    \"\"\"Calculate text-concept label similarity using CLIP\"\"\"\n",
        "    # Encode both text and labels into vectors\n",
        "    text_embeddings = clip_model.encode(text_list, convert_to_tensor=True)\n",
        "    label_embeddings = clip_model.encode(concept_labels, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    # (text_embeddings @ label_embeddings.T) will result in a [len(text_list), len(concept_labels)] matrix\n",
        "    similarity_scores = torch.nn.functional.cosine_similarity(text_embeddings.unsqueeze(1), label_embeddings.unsqueeze(0), dim=-1)\n",
        "\n",
        "    # Apply softmax to similarity scores to make them more like probabilities\n",
        "    probabilities = softmax(similarity_scores, dim=1)\n",
        "    predictions = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "    return predictions, probabilities\n",
        "\n",
        "# Define the concepts we want to compare\n",
        "concept_labels = [\"a neutral statement\", \"a sexist statement\"]\n",
        "\n",
        "# Run CLIP analysis\n",
        "clip_predictions, clip_probabilities = analyze_with_clip(texts, concept_labels)\n",
        "\n",
        "print(\"\\n--- CLIP Zero-Shot Classification Results ---\")\n",
        "for i, text in enumerate(texts):\n",
        "    predicted_concept = concept_labels[clip_predictions[i].item()]\n",
        "    label = \"Sexist\" if \"sexist\" in predicted_concept else \"Non-sexist\"\n",
        "    print(f\"Text: '{text}'\\nPrediction: {label} (More similar to '{predicted_concept}', Confidence: {clip_probabilities[i][clip_predictions[i]].item():.4f})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i4jG2nxfsVA",
        "outputId": "2df4acfe-ea37-4364-d27e-972d0ed6cfee"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- CLIP Zero-Shot Classification Results ---\n",
            "Text: 'Women belong in the kitchen.'\n",
            "Prediction: Sexist (More similar to 'a sexist statement', Confidence: 0.5107)\n",
            "\n",
            "Text: 'He is too emotional to be a leader, just like a woman.'\n",
            "Prediction: Sexist (More similar to 'a sexist statement', Confidence: 0.5097)\n",
            "\n",
            "Text: 'The new software update will be released tomorrow.'\n",
            "Prediction: Non-sexist (More similar to 'a neutral statement', Confidence: 0.5024)\n",
            "\n",
            "Text: 'She was promoted because of her skills and hard work.'\n",
            "Prediction: Sexist (More similar to 'a sexist statement', Confidence: 0.5061)\n",
            "\n",
            "Text: 'Girls are not good at math.'\n",
            "Prediction: Sexist (More similar to 'a sexist statement', Confidence: 0.5108)\n",
            "\n",
            "Text: 'This is a great achievement for all the scientists involved.one time I sucked d**k so hard that I looked at myself in the mirror and was like holy shiiit I’m so ugly &amp; he was like “you look like a whore. I love it!” LMAOOOOO'\n",
            "Prediction: Sexist (More similar to 'a sexist statement', Confidence: 0.5093)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Integrated Analysis Results ---\")\n",
        "for i, text in enumerate(texts):\n",
        "    # BERT predicts sexist (label 1)\n",
        "    is_sexist_bert = bert_predictions[i].item() == 1\n",
        "    # CLIP predicts sexist (label 1, corresponding to 'a sexist statement')\n",
        "    is_sexist_clip = clip_predictions[i].item() == 1\n",
        "\n",
        "    final_decision = \"Potentially Sexist\" if is_sexist_bert or is_sexist_clip else \"Non-sexist\"\n",
        "\n",
        "    print(f\"Text: '{text}'\")\n",
        "    print(f\"  - BERT Prediction: {'Sexist' if is_sexist_bert else 'Non-sexist'}\")\n",
        "    print(f\"  - CLIP Prediction: {'Sexist' if is_sexist_clip else 'Non-sexist'}\")\n",
        "    print(f\"  - Final Conclusion: **{final_decision}**\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb-VeXgofwzx",
        "outputId": "70d148e0-8411-4a9e-e253-ca0a2602ebff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Integrated Analysis Results ---\n",
            "Text: 'Women belong in the kitchen.'\n",
            "  - BERT Prediction: Non-sexist\n",
            "  - CLIP Prediction: Sexist\n",
            "  - Final Conclusion: **Potentially Sexist**\n",
            "\n",
            "Text: 'He is too emotional to be a leader, just like a woman.'\n",
            "  - BERT Prediction: Non-sexist\n",
            "  - CLIP Prediction: Sexist\n",
            "  - Final Conclusion: **Potentially Sexist**\n",
            "\n",
            "Text: 'The new software update will be released tomorrow.'\n",
            "  - BERT Prediction: Non-sexist\n",
            "  - CLIP Prediction: Non-sexist\n",
            "  - Final Conclusion: **Non-sexist**\n",
            "\n",
            "Text: 'She was promoted because of her skills and hard work.'\n",
            "  - BERT Prediction: Non-sexist\n",
            "  - CLIP Prediction: Sexist\n",
            "  - Final Conclusion: **Potentially Sexist**\n",
            "\n",
            "Text: 'Girls are not good at math.'\n",
            "  - BERT Prediction: Non-sexist\n",
            "  - CLIP Prediction: Sexist\n",
            "  - Final Conclusion: **Potentially Sexist**\n",
            "\n",
            "Text: 'This is a great achievement for all the scientists involved.one time I sucked d**k so hard that I looked at myself in the mirror and was like holy shiiit I’m so ugly &amp; he was like “you look like a whore. I love it!” LMAOOOOO'\n",
            "  - BERT Prediction: Non-sexist\n",
            "  - CLIP Prediction: Sexist\n",
            "  - Final Conclusion: **Potentially Sexist**\n",
            "\n"
          ]
        }
      ]
    }
  ]
}