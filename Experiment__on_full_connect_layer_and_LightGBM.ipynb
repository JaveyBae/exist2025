{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NfC_ZL6WdQ-",
        "outputId": "1828e0e7-2297-4bab-f1b5-c82831e78356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.10.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1PbdlIg0p8Lm8HO2Wv17b5vzelXONpbuf\n",
            "From (redirected): https://drive.google.com/uc?id=1PbdlIg0p8Lm8HO2Wv17b5vzelXONpbuf&confirm=t&uuid=6027f07b-8709-40e1-ae02-086783c0b469\n",
            "To: /content/memes.zip\n",
            "100%|██████████| 557M/557M [00:02<00:00, 267MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WhUQxJ2b1SjY5geBmthr8CvnR2GTt5l4\n",
            "To: /content/processed_data_all_labels.csv\n",
            "100%|██████████| 1.04M/1.04M [00:00<00:00, 152MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction complete for memes.zip. Files are located at: /content/\n"
          ]
        }
      ],
      "source": [
        "!pip install -U gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "# 第一个文件\n",
        "url1 = \"https://drive.google.com/uc?id=1PbdlIg0p8Lm8HO2Wv17b5vzelXONpbuf\"\n",
        "output1 = \"memes.zip\"  # 你可以改成实际文件名或路径\n",
        "gdown.download(url1, output1, quiet=False)\n",
        "\n",
        "# 第二个文件\n",
        "url2 = \"https://drive.google.com/uc?id=1WhUQxJ2b1SjY5geBmthr8CvnR2GTt5l4\"\n",
        "output2 = \"processed_data_all_labels.csv\"\n",
        "gdown.download(url2, output2, quiet=False)\n",
        "\n",
        "# Unzip the downloaded file file1.ext\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the zip file path\n",
        "zip_path = '/content/memes.zip' # Path to file1.ext\n",
        "extract_dir = '/content/'  # Extract to Colab local storage (assuming this contains the images)\n",
        "\n",
        "# Create extraction directory\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Check if the zip file exists\n",
        "if not os.path.exists(zip_path):\n",
        "    print(f\"❌ Error: Zip file not found at {zip_path}\")\n",
        "else:\n",
        "    # Extract the zip file\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "        print(f\"✅ Extraction complete for {os.path.basename(zip_path)}. Files are located at: {extract_dir}\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"❌ Error: File at {zip_path} is not a valid zip file.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An unexpected error occurred during extraction of {os.path.basename(zip_path)}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------\n",
        "# 1. 基础库 & 设备\n",
        "# --------------------------------------------------------------\n",
        "import os, ast, torch, numpy as np, pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2. 数据集定义（和你的原始代码完全一致）\n",
        "# --------------------------------------------------------------\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = str(self.df.iloc[idx]['id'])\n",
        "        # 尝试多种后缀\n",
        "        for ext in ['.jpeg', '.jpg', '.png', '.JPEG', '.JPG', '.PNG']:\n",
        "            path = os.path.join(self.image_dir, img_id + ext)\n",
        "            if os.path.exists(path):\n",
        "                img = Image.open(path).convert(\"RGB\")\n",
        "                break\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Image not found: {img_id}\")\n",
        "\n",
        "        text = self.df.iloc[idx]['text']\n",
        "\n",
        "        # ---- task4_hard 是二分类 one-hot ----\n",
        "        hard = ast.literal_eval(self.df.iloc[idx]['task4_hard'])\n",
        "        label = torch.tensor(hard.index(1.0), dtype=torch.float)   # 0 or 1\n",
        "\n",
        "        return {'image': img, 'text': text, 'label': label}\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'image': [b['image'] for b in batch],\n",
        "        'text' : [b['text']  for b in batch],\n",
        "        'label': torch.stack([b['label'] for b in batch])\n",
        "    }\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3. 加载数据 & 划分\n",
        "# --------------------------------------------------------------\n",
        "CSV_PATH   = 'processed_data_all_labels.csv'\n",
        "IMAGE_DIR  = '/content/memes/'          # 你的图片所在文件夹\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "full_ds = MemeDataset(CSV_PATH, IMAGE_DIR)\n",
        "train_sz = int(0.8 * len(full_ds))\n",
        "val_sz   = int(0.1 * len(full_ds))\n",
        "test_sz  = len(full_ds) - train_sz - val_sz\n",
        "train_ds, val_ds, test_ds = random_split(full_ds, [train_sz, val_sz, test_sz])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True , collate_fn=collate_fn)\n",
        "test_loader  = DataLoader(test_ds , batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Train/Val/Test: {train_sz}/{val_sz}/{test_sz}\")\n",
        "\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4. 多模态特征提取（CLIP + RoBERTa）—— 修复设备不一致\n",
        "# --------------------------------------------------------------\n",
        "clip_model   = SentenceTransformer('clip-ViT-B-32')\n",
        "roberta      = RobertaModel.from_pretrained('roberta-base').to(device)   # ← 移动到 GPU\n",
        "tokenizer    = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta.eval()\n",
        "clip_model.eval()\n",
        "\n",
        "def extract_features(loader):\n",
        "    img_embs, txt_embs, lbls = [], [], []\n",
        "    for batch in tqdm(loader, desc=\"Extracting\"):\n",
        "        imgs = batch['image']\n",
        "        txts = batch['text']\n",
        "        lbl  = batch['label'].to(device)\n",
        "\n",
        "        # ---- CLIP 图像 ----\n",
        "        img_feat = clip_model.encode(\n",
        "            imgs,\n",
        "            convert_to_tensor=True,\n",
        "            show_progress_bar=False,\n",
        "            device=device  # ← 关键！指定设备\n",
        "        )\n",
        "\n",
        "        # ---- RoBERTa 文本 ----\n",
        "        enc = tokenizer(\n",
        "            txts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        # 确保所有 tensor 都在同一个设备\n",
        "        enc = {k: v.to(device) for k, v in enc.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            txt_feat = roberta(**enc).last_hidden_state.mean(dim=1)   # [B, 768]\n",
        "\n",
        "        img_embs.append(img_feat)\n",
        "        txt_embs.append(txt_feat)\n",
        "        lbls.append(lbl)\n",
        "\n",
        "    img_all = torch.cat(img_embs, dim=0)\n",
        "    txt_all = torch.cat(txt_embs, dim=0)\n",
        "    lbl_all = torch.cat(lbls, dim=0)\n",
        "    return torch.cat([img_all, txt_all], dim=1), lbl_all\n",
        "\n",
        "print(\"\\n--- Extracting TRAIN features ---\")\n",
        "train_features, train_labels = extract_features(train_loader)\n",
        "\n",
        "print(\"\\n--- Extracting TEST features ---\")\n",
        "test_features , test_labels  = extract_features(test_loader)\n",
        "\n",
        "print(f\"train_features: {train_features.shape}, train_labels: {train_labels.shape}\")\n",
        "print(f\"test_features : {test_features.shape},  test_labels : {test_labels.shape}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5. 特征标准化（对 FC 和 LightGBM 都至关重要）\n",
        "# --------------------------------------------------------------\n",
        "scaler = StandardScaler()\n",
        "train_feat_np = train_features.cpu().numpy()\n",
        "test_feat_np  = test_features.cpu().numpy()\n",
        "\n",
        "train_feat_scaled = scaler.fit_transform(train_feat_np)\n",
        "test_feat_scaled  = scaler.transform(test_feat_np)\n",
        "\n",
        "train_features = torch.FloatTensor(train_feat_scaled).to(device)\n",
        "test_features  = torch.FloatTensor(test_feat_scaled ).to(device)\n",
        "\n",
        "print(\"Features standardized\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 6. 更强的 Fully-Connected 模型\n",
        "# --------------------------------------------------------------\n",
        "class StrongFC(nn.Module):\n",
        "    def __init__(self, input_dim, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(256, 128),       nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(dropout*0.8),\n",
        "            nn.Linear(128, 64),        nn.BatchNorm1d(64),  nn.ReLU(), nn.Dropout(dropout*0.6),\n",
        "            nn.Linear(64, 1)                                      # 二分类 logits\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "fc_model = StrongFC(train_features.shape[1]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(fc_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "train_ds_fc = TensorDataset(train_features, train_labels.to(device))\n",
        "test_ds_fc  = TensorDataset(test_features , test_labels .to(device))\n",
        "\n",
        "train_loader_fc = DataLoader(train_ds_fc, batch_size=32, shuffle=True)\n",
        "test_loader_fc  = DataLoader(test_ds_fc , batch_size=32, shuffle=False)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 7. 训练 StrongFC（带简单早停）\n",
        "# --------------------------------------------------------------\n",
        "print(\"\\n--- Training StrongFC ---\")\n",
        "fc_model.train()\n",
        "EPOCHS = 50\n",
        "best_val_acc = 0.0\n",
        "patience = 7\n",
        "no_imp = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0.0\n",
        "    for x, y in train_loader_fc:\n",
        "        optimizer.zero_grad()\n",
        "        logits = fc_model(x).squeeze(1)\n",
        "        loss   = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # ---- 验证（使用最后 10% 的训练集做快速验证）----\n",
        "    fc_model.eval()\n",
        "    val_preds, val_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(train_loader_fc):\n",
        "            if i > len(train_loader_fc) * 0.9:   # 最后 10%\n",
        "                prob = torch.sigmoid(fc_model(x)).cpu().numpy()\n",
        "                val_preds.extend((prob > 0.5).astype(int).flatten())\n",
        "                val_true.extend(y.cpu().numpy().astype(int))\n",
        "    val_acc = accuracy_score(val_true, val_preds)\n",
        "    fc_model.train()\n",
        "\n",
        "    print(f\"Epoch {epoch+1:2d} | Loss {epoch_loss/len(train_loader_fc):.4f} | ValAcc {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(fc_model.state_dict(), 'best_fc.pth')\n",
        "        no_imp = 0\n",
        "    else:\n",
        "        no_imp += 1\n",
        "        if no_imp >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "fc_model.load_state_dict(torch.load('best_fc.pth'))\n",
        "print(f\"StrongFC 训练结束，Best Val Acc: {best_val_acc:.4f}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 8. 调优 LightGBM\n",
        "# --------------------------------------------------------------\n",
        "print(\"\\n--- Training Tuned LightGBM ---\")\n",
        "lgb_train = lgb.Dataset(train_feat_scaled, label=train_labels.cpu().numpy())\n",
        "\n",
        "params = {\n",
        "    'objective'       : 'binary',\n",
        "    'metric'          : 'binary_logloss',\n",
        "    'boosting_type'   : 'gbdt',\n",
        "    'num_leaves'      : 64,\n",
        "    'max_depth'       : 10,\n",
        "    'learning_rate'   : 0.05,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq'    : 5,\n",
        "    'verbose'         : -1,\n",
        "    'seed'            : 42\n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(\n",
        "    params,\n",
        "    lgb_train,\n",
        "    num_boost_round=1000,\n",
        "    valid_sets=[lgb_train],\n",
        "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
        ")\n",
        "\n",
        "print(\"LightGBM 训练完成\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 9. 集成预测（FC + LightGBM 软投票）\n",
        "# --------------------------------------------------------------\n",
        "print(\"\\n--- Ensemble (FC + LightGBM) ---\")\n",
        "fc_model.eval()\n",
        "fc_probs = []\n",
        "with torch.no_grad():\n",
        "    for x, _ in test_loader_fc:\n",
        "        prob = torch.sigmoid(fc_model(x)).cpu().numpy().flatten()\n",
        "        fc_probs.extend(prob)\n",
        "\n",
        "lgb_probs = lgb_model.predict(test_feat_scaled)\n",
        "\n",
        "ensemble_prob = (np.array(fc_probs) + np.array(lgb_probs)) / 2\n",
        "ensemble_pred = (ensemble_prob > 0.5).astype(int)\n",
        "\n",
        "ens_acc = accuracy_score(test_labels.cpu().numpy(), ensemble_pred)\n",
        "fc_acc  = accuracy_score(test_labels.cpu().numpy(), (np.array(fc_probs) > 0.5).astype(int))\n",
        "lgb_acc = accuracy_score(test_labels.cpu().numpy(), (np.array(lgb_probs) > 0.5).astype(int))\n",
        "\n",
        "print(\"\\nFINAL RESULTS\")\n",
        "print(f\"   StrongFC alone : {fc_acc:.4f}\")\n",
        "print(f\"   LightGBM alone : {lgb_acc:.4f}\")\n",
        "print(f\"   ENSEMBLE       : {ens_acc:.4f}  (↑)\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 10. （可选）保存模型供后续推理\n",
        "# --------------------------------------------------------------\n",
        "torch.save(fc_model.state_dict(), 'fc_final.pth')\n",
        "lgb_model.save_model('lgb_final.txt')\n",
        "print(\"\\n模型已保存：fc_final.pth  &  lgb_final.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwAKa1HjYdot",
        "outputId": "e672a828-fac9-4971-e7a7-d01ba578927d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Train/Val/Test: 3235/404/405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Extracting TRAIN features ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting: 100%|██████████| 203/203 [01:09<00:00,  2.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Extracting TEST features ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting: 100%|██████████| 26/26 [00:08<00:00,  2.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_features: torch.Size([3235, 1280]), train_labels: torch.Size([3235])\n",
            "test_features : torch.Size([405, 1280]),  test_labels : torch.Size([405])\n",
            "Features standardized\n",
            "\n",
            "--- Training StrongFC ---\n",
            "Epoch  1 | Loss 0.6834 | ValAcc 0.6735\n",
            "Epoch  2 | Loss 0.6406 | ValAcc 0.7526\n",
            "Epoch  3 | Loss 0.6089 | ValAcc 0.7354\n",
            "Epoch  4 | Loss 0.5711 | ValAcc 0.7285\n",
            "Epoch  5 | Loss 0.5508 | ValAcc 0.7526\n",
            "Epoch  6 | Loss 0.5328 | ValAcc 0.8041\n",
            "Epoch  7 | Loss 0.5125 | ValAcc 0.8316\n",
            "Epoch  8 | Loss 0.4622 | ValAcc 0.8625\n",
            "Epoch  9 | Loss 0.4614 | ValAcc 0.8419\n",
            "Epoch 10 | Loss 0.4577 | ValAcc 0.8591\n",
            "Epoch 11 | Loss 0.4240 | ValAcc 0.8935\n",
            "Epoch 12 | Loss 0.4082 | ValAcc 0.8797\n",
            "Epoch 13 | Loss 0.3779 | ValAcc 0.9038\n",
            "Epoch 14 | Loss 0.3522 | ValAcc 0.9072\n",
            "Epoch 15 | Loss 0.3532 | ValAcc 0.9381\n",
            "Epoch 16 | Loss 0.3540 | ValAcc 0.9416\n",
            "Epoch 17 | Loss 0.3436 | ValAcc 0.9210\n",
            "Epoch 18 | Loss 0.3144 | ValAcc 0.9313\n",
            "Epoch 19 | Loss 0.2881 | ValAcc 0.9519\n",
            "Epoch 20 | Loss 0.3168 | ValAcc 0.9725\n",
            "Epoch 21 | Loss 0.2971 | ValAcc 0.9622\n",
            "Epoch 22 | Loss 0.2789 | ValAcc 0.9828\n",
            "Epoch 23 | Loss 0.2683 | ValAcc 0.9588\n",
            "Epoch 24 | Loss 0.2806 | ValAcc 0.9656\n",
            "Epoch 25 | Loss 0.3128 | ValAcc 0.9897\n",
            "Epoch 26 | Loss 0.2816 | ValAcc 0.9588\n",
            "Epoch 27 | Loss 0.2507 | ValAcc 0.9450\n",
            "Epoch 28 | Loss 0.2516 | ValAcc 0.9794\n",
            "Epoch 29 | Loss 0.2223 | ValAcc 0.9897\n",
            "Epoch 30 | Loss 0.2202 | ValAcc 0.9656\n",
            "Epoch 31 | Loss 0.2292 | ValAcc 0.9794\n",
            "Epoch 32 | Loss 0.2401 | ValAcc 0.9828\n",
            "Early stopping triggered\n",
            "StrongFC 训练结束，Best Val Acc: 0.9897\n",
            "\n",
            "--- Training Tuned LightGBM ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\ttraining's binary_logloss: 0.125742\n",
            "[200]\ttraining's binary_logloss: 0.0325101\n",
            "[300]\ttraining's binary_logloss: 0.00978492\n",
            "[400]\ttraining's binary_logloss: 0.00363531\n",
            "[500]\ttraining's binary_logloss: 0.00163878\n",
            "[600]\ttraining's binary_logloss: 0.00109747\n",
            "[700]\ttraining's binary_logloss: 0.000939614\n",
            "[800]\ttraining's binary_logloss: 0.000913539\n",
            "[900]\ttraining's binary_logloss: 0.000887917\n",
            "[1000]\ttraining's binary_logloss: 0.000877412\n",
            "LightGBM 训练完成\n",
            "\n",
            "--- Ensemble (FC + LightGBM) ---\n",
            "\n",
            "FINAL RESULTS\n",
            "   StrongFC alone : 0.6148\n",
            "   LightGBM alone : 0.6840\n",
            "   ENSEMBLE       : 0.6741  (↑)\n",
            "\n",
            "模型已保存：fc_final.pth  &  lgb_final.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a95838c6",
        "outputId": "0dd06c79-3ba4-4857-d995-2a9813715c17"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Assuming test_labels, fc_probs, lgb_probs, and ensemble_pred are available from the previous cell\n",
        "\n",
        "# Calculate F1 scores\n",
        "test_labels_np = test_labels.cpu().numpy()\n",
        "fc_preds = (np.array(fc_probs) > 0.5).astype(int)\n",
        "lgb_preds = (np.array(lgb_probs) > 0.5).astype(int)\n",
        "\n",
        "\n",
        "ens_f1 = f1_score(test_labels_np, ensemble_pred)\n",
        "fc_f1  = f1_score(test_labels_np, fc_preds)\n",
        "lgb_f1 = f1_score(test_labels_np, lgb_preds)\n",
        "\n",
        "print(\"\\nF1 SCORES\")\n",
        "print(f\"   StrongFC alone : {fc_f1:.4f}\")\n",
        "print(f\"   LightGBM alone : {lgb_f1:.4f}\")\n",
        "print(f\"   ENSEMBLE       : {ens_f1:.4f}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "F1 SCORES\n",
            "   StrongFC alone : 0.5618\n",
            "   LightGBM alone : 0.5789\n",
            "   ENSEMBLE       : 0.5901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the experiment on soft label"
      ],
      "metadata": {
        "id": "KtbOF826hq-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------\n",
        "# 1. 基础库 & 设备\n",
        "# --------------------------------------------------------------\n",
        "import os, ast, torch, numpy as np, pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 2. 数据集定义（使用 soft label）\n",
        "# --------------------------------------------------------------\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def __len__(self): return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = str(self.df.iloc[idx]['id'])\n",
        "        for ext in ['.jpeg', '.jpg', '.png', '.JPEG', '.JPG', '.PNG']:\n",
        "            path = os.path.join(self.image_dir, img_id + ext)\n",
        "            if os.path.exists(path):\n",
        "                img = Image.open(path).convert(\"RGB\")\n",
        "                break\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Image not found: {img_id}\")\n",
        "\n",
        "        text = self.df.iloc[idx]['text']\n",
        "\n",
        "        # ---- soft label ----\n",
        "        soft = ast.literal_eval(self.df.iloc[idx]['task4_soft'])\n",
        "        label = torch.tensor(soft[1], dtype=torch.float)  # [0,1] 之间的软标签\n",
        "\n",
        "        return {'image': img, 'text': text, 'label': label}\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'image': [b['image'] for b in batch],\n",
        "        'text' : [b['text']  for b in batch],\n",
        "        'label': torch.stack([b['label'] for b in batch])\n",
        "    }\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 3. 加载数据 & 划分\n",
        "# --------------------------------------------------------------\n",
        "CSV_PATH   = 'processed_data_all_labels.csv'\n",
        "IMAGE_DIR  = '/content/memes/'\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "full_ds = MemeDataset(CSV_PATH, IMAGE_DIR)\n",
        "train_sz = int(0.8 * len(full_ds))\n",
        "val_sz   = int(0.1 * len(full_ds))\n",
        "test_sz  = len(full_ds) - train_sz - val_sz\n",
        "train_ds, val_ds, test_ds = random_split(full_ds, [train_sz, val_sz, test_sz])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True , collate_fn=collate_fn)\n",
        "test_loader  = DataLoader(test_ds , batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"Train/Val/Test: {train_sz}/{val_sz}/{test_sz}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 4. 多模态特征提取（CLIP + RoBERTa）\n",
        "# --------------------------------------------------------------\n",
        "clip_model   = SentenceTransformer('clip-ViT-B-32').to(device) # Move CLIP model to device\n",
        "roberta      = RobertaModel.from_pretrained('roberta-base').to(device) # Ensure Roberta is on the correct device\n",
        "tokenizer    = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta.eval()\n",
        "clip_model.eval()\n",
        "\n",
        "def extract_features(loader):\n",
        "    img_embs, txt_embs, lbls = [], [], []\n",
        "    for batch in tqdm(loader, desc=\"Extracting\"):\n",
        "        imgs = batch['image']\n",
        "        txts = batch['text']\n",
        "        lbl  = batch['label'].to(device)\n",
        "\n",
        "        img_feat = clip_model.encode(imgs, convert_to_tensor=True, show_progress_bar=False).to(device) # Move image features to device after encoding\n",
        "\n",
        "        enc = tokenizer(txts, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "        enc = {k: v.to(device) for k, v in enc.items()} # Ensure input tensors are on the correct device\n",
        "        with torch.no_grad():\n",
        "            txt_feat = roberta(**enc).last_hidden_state.mean(dim=1)\n",
        "\n",
        "        img_embs.append(img_feat)\n",
        "        txt_embs.append(txt_feat)\n",
        "        lbls.append(lbl)\n",
        "\n",
        "    img_all = torch.cat(img_embs, dim=0)\n",
        "    txt_all = torch.cat(txt_embs, dim=0)\n",
        "    lbl_all = torch.cat(lbls, dim=0)\n",
        "    return torch.cat([img_all, txt_all], dim=1), lbl_all\n",
        "\n",
        "print(\"\\n--- Extracting TRAIN features ---\")\n",
        "train_features, train_labels = extract_features(train_loader)\n",
        "print(\"\\n--- Extracting TEST features ---\")\n",
        "test_features , test_labels  = extract_features(test_loader)\n",
        "\n",
        "print(f\"train_features: {train_features.shape}, train_labels: {train_labels.shape}\")\n",
        "print(f\"test_features : {test_features.shape},  test_labels : {test_labels.shape}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 5. 特征标准化\n",
        "# --------------------------------------------------------------\n",
        "scaler = StandardScaler()\n",
        "train_feat_np = train_features.cpu().numpy()\n",
        "test_feat_np  = test_features.cpu().numpy()\n",
        "train_feat_scaled = scaler.fit_transform(train_feat_np)\n",
        "test_feat_scaled  = scaler.transform(test_feat_np)\n",
        "train_features = torch.FloatTensor(train_feat_scaled).to(device)\n",
        "test_features  = torch.FloatTensor(test_feat_scaled ).to(device)\n",
        "print(\"Features standardized\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 6. Fully Connected 模型\n",
        "# --------------------------------------------------------------\n",
        "class StrongFC(nn.Module):\n",
        "    def __init__(self, input_dim, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(256, 128),       nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(dropout*0.8),\n",
        "            nn.Linear(128, 64),        nn.BatchNorm1d(64),  nn.ReLU(), nn.Dropout(dropout*0.6),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "fc_model = StrongFC(train_features.shape[1]).to(device)\n",
        "\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "kl  = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "def mixed_loss(logits, targets):\n",
        "    prob = torch.sigmoid(logits)\n",
        "    loss_bce = bce(logits, targets)\n",
        "    loss_kl  = kl(prob.log(), targets)\n",
        "    return 0.7 * loss_bce + 0.3 * loss_kl\n",
        "\n",
        "optimizer = torch.optim.AdamW(fc_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "train_ds_fc = TensorDataset(train_features, train_labels.to(device))\n",
        "test_ds_fc  = TensorDataset(test_features , test_labels .to(device))\n",
        "train_loader_fc = DataLoader(train_ds_fc, batch_size=32, shuffle=True)\n",
        "test_loader_fc  = DataLoader(test_ds_fc , batch_size=32, shuffle=False)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 7. 训练 StrongFC\n",
        "# --------------------------------------------------------------\n",
        "print(\"\\n--- Training StrongFC (Soft Label) ---\")\n",
        "fc_model.train()\n",
        "EPOCHS = 50\n",
        "best_val_acc = 0.0\n",
        "patience = 7\n",
        "no_imp = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0.0\n",
        "    for x, y in train_loader_fc:\n",
        "        optimizer.zero_grad()\n",
        "        logits = fc_model(x).squeeze(1)\n",
        "        loss   = mixed_loss(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    fc_model.eval()\n",
        "    preds, true = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader_fc:\n",
        "            prob = torch.sigmoid(fc_model(x)).cpu().numpy()\n",
        "            preds.extend(prob.flatten())\n",
        "            true.extend(y.cpu().numpy())\n",
        "    fc_model.train()\n",
        "\n",
        "    preds_bin = (np.array(preds) > 0.5).astype(int)\n",
        "    true_bin  = (np.array(true) > 0.5).astype(int)\n",
        "    val_acc = accuracy_score(true_bin, preds_bin)\n",
        "    val_f1  = f1_score(true_bin, preds_bin, average='macro')\n",
        "\n",
        "    print(f\"Epoch {epoch+1:2d} | Loss {epoch_loss/len(train_loader_fc):.4f} | ValAcc {val_acc:.4f} | ValF1 {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_acc:\n",
        "        best_val_acc = val_f1\n",
        "        torch.save(fc_model.state_dict(), 'best_fc_soft.pth')\n",
        "        no_imp = 0\n",
        "    else:\n",
        "        no_imp += 1\n",
        "        if no_imp >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "fc_model.load_state_dict(torch.load('best_fc_soft.pth'))\n",
        "print(f\"StrongFC 训练结束，Best Val F1: {best_val_acc:.4f}\")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 8. LightGBM (Soft label)\n",
        "# --------------------------------------------------------------\n",
        "print(\"\\n--- Training LightGBM (Soft Label) ---\")\n",
        "lgb_train = lgb.Dataset(train_feat_scaled, label=train_labels.cpu().numpy())\n",
        "\n",
        "params = {\n",
        "    'objective'       : 'binary',\n",
        "    'metric'          : 'binary_logloss',\n",
        "    'boosting_type'   : 'gbdt',\n",
        "    'num_leaves'      : 64,\n",
        "    'max_depth'       : 10,\n",
        "    'learning_rate'   : 0.05,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq'    : 5,\n",
        "    'verbose'         : -1,\n",
        "    'seed'            : 42\n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(\n",
        "    params,\n",
        "    lgb_train,\n",
        "    num_boost_round=1000,\n",
        "    valid_sets=[lgb_train],\n",
        "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
        ")\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# 9. 集成评估\n",
        "# --------------------------------------------------------------\n",
        "print(\"\\n--- Ensemble Evaluation (Soft Label) ---\")\n",
        "fc_model.eval()\n",
        "fc_probs = []\n",
        "with torch.no_grad():\n",
        "    for x, _ in test_loader_fc:\n",
        "        prob = torch.sigmoid(fc_model(x)).cpu().numpy().flatten()\n",
        "        fc_probs.extend(prob)\n",
        "\n",
        "lgb_probs = lgb_model.predict(test_feat_scaled)\n",
        "\n",
        "ensemble_prob = (np.array(fc_probs) + np.array(lgb_probs)) / 2\n",
        "ensemble_pred = (ensemble_prob > 0.5).astype(int)\n",
        "\n",
        "# True labels (二值化)\n",
        "y_true = (test_labels.cpu().numpy() > 0.5).astype(int)\n",
        "\n",
        "# Metrics\n",
        "def report(name, probs, preds):\n",
        "    acc = accuracy_score(y_true, preds)\n",
        "    f1  = f1_score(y_true, preds, average='macro')\n",
        "    print(f\"{name:<15} Acc: {acc:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nFINAL RESULTS (Soft Label Training)\")\n",
        "report(\"StrongFC\", fc_probs, (np.array(fc_probs) > 0.5).astype(int))\n",
        "report(\"LightGBM\", lgb_probs, (np.array(lgb_probs) > 0.5).astype(int))\n",
        "report(\"Ensemble\", ensemble_prob, ensemble_pred)\n",
        "\n",
        "torch.save(fc_model.state_dict(), 'fc_final_soft.pth')\n",
        "lgb_model.save_model('lgb_final_soft.txt')\n",
        "print(\"\\n模型已保存：fc_final_soft.pth  &  lgb_final_soft.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RkquuZQhzyK",
        "outputId": "07b4646b-b541-43cf-b666-360bba17f13d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Train/Val/Test: 3235/404/405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Extracting TRAIN features ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting:  16%|█▋        | 33/203 [00:13<01:09,  2.43it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Extracting: 100%|██████████| 203/203 [01:14<00:00,  2.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Extracting TEST features ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting: 100%|██████████| 26/26 [00:09<00:00,  2.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_features: torch.Size([3235, 1280]), train_labels: torch.Size([3235])\n",
            "test_features : torch.Size([405, 1280]),  test_labels : torch.Size([405])\n",
            "Features standardized\n",
            "\n",
            "--- Training StrongFC (Soft Label) ---\n",
            "Epoch  1 | Loss 0.5157 | ValAcc 0.6000 | ValF1 0.5966\n",
            "Epoch  2 | Loss 0.4902 | ValAcc 0.6049 | ValF1 0.5991\n",
            "Epoch  3 | Loss 0.4827 | ValAcc 0.5975 | ValF1 0.5902\n",
            "Epoch  4 | Loss 0.4732 | ValAcc 0.6198 | ValF1 0.6162\n",
            "Epoch  5 | Loss 0.4630 | ValAcc 0.6247 | ValF1 0.6166\n",
            "Epoch  6 | Loss 0.4556 | ValAcc 0.6395 | ValF1 0.6300\n",
            "Epoch  7 | Loss 0.4508 | ValAcc 0.6420 | ValF1 0.6296\n",
            "Epoch  8 | Loss 0.4443 | ValAcc 0.6370 | ValF1 0.6231\n",
            "Epoch  9 | Loss 0.4415 | ValAcc 0.6420 | ValF1 0.6282\n",
            "Epoch 10 | Loss 0.4379 | ValAcc 0.6198 | ValF1 0.6141\n",
            "Epoch 11 | Loss 0.4315 | ValAcc 0.6469 | ValF1 0.6367\n",
            "Epoch 12 | Loss 0.4219 | ValAcc 0.6346 | ValF1 0.6243\n",
            "Epoch 13 | Loss 0.4239 | ValAcc 0.6444 | ValF1 0.6356\n",
            "Epoch 14 | Loss 0.4154 | ValAcc 0.6395 | ValF1 0.6294\n",
            "Epoch 15 | Loss 0.4157 | ValAcc 0.6247 | ValF1 0.6176\n",
            "Epoch 16 | Loss 0.4085 | ValAcc 0.6444 | ValF1 0.6272\n",
            "Epoch 17 | Loss 0.4165 | ValAcc 0.6346 | ValF1 0.6201\n",
            "Epoch 18 | Loss 0.4064 | ValAcc 0.6543 | ValF1 0.6384\n",
            "Epoch 19 | Loss 0.4060 | ValAcc 0.6494 | ValF1 0.6383\n",
            "Epoch 20 | Loss 0.4032 | ValAcc 0.6074 | ValF1 0.6018\n",
            "Epoch 21 | Loss 0.4022 | ValAcc 0.6272 | ValF1 0.6204\n",
            "Epoch 22 | Loss 0.3933 | ValAcc 0.6025 | ValF1 0.5993\n",
            "Epoch 23 | Loss 0.3891 | ValAcc 0.6198 | ValF1 0.6158\n",
            "Epoch 24 | Loss 0.3855 | ValAcc 0.6741 | ValF1 0.6551\n",
            "Epoch 25 | Loss 0.3867 | ValAcc 0.6198 | ValF1 0.6109\n",
            "Epoch 26 | Loss 0.3877 | ValAcc 0.6321 | ValF1 0.6254\n",
            "Epoch 27 | Loss 0.3841 | ValAcc 0.6247 | ValF1 0.6135\n",
            "Epoch 28 | Loss 0.3875 | ValAcc 0.6444 | ValF1 0.6272\n",
            "Epoch 29 | Loss 0.3816 | ValAcc 0.5975 | ValF1 0.5918\n",
            "Epoch 30 | Loss 0.3818 | ValAcc 0.6025 | ValF1 0.5981\n",
            "Epoch 31 | Loss 0.3789 | ValAcc 0.6123 | ValF1 0.6048\n",
            "Early stopping triggered\n",
            "StrongFC 训练结束，Best Val F1: 0.6551\n",
            "\n",
            "--- Training LightGBM (Soft Label) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\ttraining's binary_logloss: 0.0439688\n",
            "[200]\ttraining's binary_logloss: 0.00767471\n",
            "[300]\ttraining's binary_logloss: 0.00208756\n",
            "[400]\ttraining's binary_logloss: 0.00108716\n",
            "[500]\ttraining's binary_logloss: 0.000924993\n",
            "[600]\ttraining's binary_logloss: 0.000965119\n",
            "[700]\ttraining's binary_logloss: 0.000868085\n",
            "[800]\ttraining's binary_logloss: 0.000893689\n",
            "[900]\ttraining's binary_logloss: 0.000915728\n",
            "[1000]\ttraining's binary_logloss: 0.000886683\n",
            "\n",
            "--- Ensemble Evaluation (Soft Label) ---\n",
            "\n",
            "FINAL RESULTS (Soft Label Training)\n",
            "StrongFC        Acc: 0.6741 | F1: 0.6551\n",
            "LightGBM        Acc: 0.3605 | F1: 0.2737\n",
            "Ensemble        Acc: 0.3630 | F1: 0.2779\n",
            "\n",
            "模型已保存：fc_final_soft.pth  &  lgb_final_soft.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# 混合策略集成训练：FC用软标签 + LightGBM用硬标签\n",
        "# ==============================================================\n",
        "\n",
        "import os, ast, torch, numpy as np, pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import lightgbm as lgb\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ==============================================================\n",
        "# 1. 数据集定义（同时支持软硬标签）\n",
        "# ==============================================================\n",
        "class MemeDataset(Dataset):\n",
        "    def __init__(self, csv_file, image_dir, use_soft=True):\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.image_dir = image_dir\n",
        "        self.use_soft = use_soft\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = str(self.df.iloc[idx]['id'])\n",
        "\n",
        "        # 加载图像\n",
        "        for ext in ['.jpeg', '.jpg', '.png', '.JPEG', '.JPG', '.PNG']:\n",
        "            path = os.path.join(self.image_dir, img_id + ext)\n",
        "            if os.path.exists(path):\n",
        "                img = Image.open(path).convert(\"RGB\")\n",
        "                break\n",
        "        else:\n",
        "            raise FileNotFoundError(f\"Image not found: {img_id}\")\n",
        "\n",
        "        text = self.df.iloc[idx]['text']\n",
        "\n",
        "        # 软标签 or 硬标签\n",
        "        if self.use_soft:\n",
        "            soft = ast.literal_eval(self.df.iloc[idx]['task4_soft'])\n",
        "            label = torch.tensor(soft[1], dtype=torch.float)  # [0,1] 软标签\n",
        "        else:\n",
        "            hard = ast.literal_eval(self.df.iloc[idx]['task4_hard'])\n",
        "            label = torch.tensor(hard.index(1.0), dtype=torch.float)  # 0 or 1\n",
        "\n",
        "        return {'image': img, 'text': text, 'label': label}\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'image': [b['image'] for b in batch],\n",
        "        'text' : [b['text']  for b in batch],\n",
        "        'label': torch.stack([b['label'] for b in batch])\n",
        "    }\n",
        "\n",
        "# ==============================================================\n",
        "# 2. 加载数据\n",
        "# ==============================================================\n",
        "CSV_PATH   = 'processed_data_all_labels.csv'\n",
        "IMAGE_DIR  = '/content/memes/'\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# 软标签数据集（用于FC）\n",
        "full_ds_soft = MemeDataset(CSV_PATH, IMAGE_DIR, use_soft=True)\n",
        "train_sz = int(0.8 * len(full_ds_soft))\n",
        "val_sz   = int(0.1 * len(full_ds_soft))\n",
        "test_sz  = len(full_ds_soft) - train_sz - val_sz\n",
        "\n",
        "train_ds_soft, val_ds_soft, test_ds_soft = random_split(\n",
        "    full_ds_soft, [train_sz, val_sz, test_sz]\n",
        ")\n",
        "\n",
        "# 硬标签数据集（用于LightGBM）\n",
        "full_ds_hard = MemeDataset(CSV_PATH, IMAGE_DIR, use_soft=False)\n",
        "train_ds_hard, val_ds_hard, test_ds_hard = random_split(\n",
        "    full_ds_hard, [train_sz, val_sz, test_sz]\n",
        ")\n",
        "\n",
        "print(f\"Train/Val/Test: {train_sz}/{val_sz}/{test_sz}\")\n",
        "\n",
        "# ==============================================================\n",
        "# 3. 多模态特征提取（共享特征）\n",
        "# ==============================================================\n",
        "clip_model = SentenceTransformer('clip-ViT-B-32').to(device)\n",
        "roberta    = RobertaModel.from_pretrained('roberta-base').to(device)\n",
        "tokenizer  = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta.eval()\n",
        "clip_model.eval()\n",
        "\n",
        "def extract_features(loader):\n",
        "    img_embs, txt_embs, lbls = [], [], []\n",
        "    for batch in tqdm(loader, desc=\"Extracting\"):\n",
        "        imgs = batch['image']\n",
        "        txts = batch['text']\n",
        "        lbl  = batch['label'].to(device)\n",
        "\n",
        "        # CLIP 图像特征\n",
        "        img_feat = clip_model.encode(\n",
        "            imgs,\n",
        "            convert_to_tensor=True,\n",
        "            show_progress_bar=False\n",
        "        ).to(device)\n",
        "\n",
        "        # RoBERTa 文本特征\n",
        "        enc = tokenizer(\n",
        "            txts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        enc = {k: v.to(device) for k, v in enc.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            txt_feat = roberta(**enc).last_hidden_state.mean(dim=1)\n",
        "\n",
        "        img_embs.append(img_feat)\n",
        "        txt_embs.append(txt_feat)\n",
        "        lbls.append(lbl)\n",
        "\n",
        "    img_all = torch.cat(img_embs, dim=0)\n",
        "    txt_all = torch.cat(txt_embs, dim=0)\n",
        "    lbl_all = torch.cat(lbls, dim=0)\n",
        "    return torch.cat([img_all, txt_all], dim=1), lbl_all\n",
        "\n",
        "# 提取软标签特征\n",
        "train_loader_soft = DataLoader(train_ds_soft, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader_soft  = DataLoader(test_ds_soft, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(\"\\n=== 提取软标签特征（用于FC）===\")\n",
        "train_features_soft, train_labels_soft = extract_features(train_loader_soft)\n",
        "test_features_soft, test_labels_soft = extract_features(test_loader_soft)\n",
        "\n",
        "# 提取硬标签特征\n",
        "train_loader_hard = DataLoader(train_ds_hard, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader_hard  = DataLoader(test_ds_hard, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(\"\\n=== 提取硬标签特征（用于LightGBM）===\")\n",
        "train_features_hard, train_labels_hard = extract_features(train_loader_hard)\n",
        "test_features_hard, test_labels_hard = extract_features(test_loader_hard)\n",
        "\n",
        "# ==============================================================\n",
        "# 4. 特征标准化\n",
        "# ==============================================================\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 软标签特征\n",
        "train_feat_soft_np = train_features_soft.cpu().numpy()\n",
        "test_feat_soft_np = test_features_soft.cpu().numpy()\n",
        "train_feat_soft_scaled = scaler.fit_transform(train_feat_soft_np)\n",
        "test_feat_soft_scaled = scaler.transform(test_feat_soft_np)\n",
        "\n",
        "# 硬标签特征（使用相同的scaler）\n",
        "train_feat_hard_np = train_features_hard.cpu().numpy()\n",
        "test_feat_hard_np = test_features_hard.cpu().numpy()\n",
        "train_feat_hard_scaled = scaler.transform(train_feat_hard_np)\n",
        "test_feat_hard_scaled = scaler.transform(test_feat_hard_np)\n",
        "\n",
        "print(\"✅ 特征标准化完成\")\n",
        "\n",
        "# ==============================================================\n",
        "# 5. 定义 FC 模型（用软标签训练）\n",
        "# ==============================================================\n",
        "class StrongFC(nn.Module):\n",
        "    def __init__(self, input_dim, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout),\n",
        "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(dropout*0.8),\n",
        "            nn.Linear(128, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(dropout*0.6),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 混合损失函数\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "kl = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "def mixed_loss(logits, targets):\n",
        "    prob = torch.sigmoid(logits)\n",
        "    loss_bce = bce(logits, targets)\n",
        "    loss_kl = kl(prob.log(), targets)\n",
        "    return 0.7 * loss_bce + 0.3 * loss_kl\n",
        "\n",
        "# 初始化模型\n",
        "fc_model = StrongFC(train_feat_soft_scaled.shape[1]).to(device)\n",
        "optimizer = torch.optim.AdamW(fc_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "train_features_soft_tensor = torch.FloatTensor(train_feat_soft_scaled).to(device)\n",
        "test_features_soft_tensor = torch.FloatTensor(test_feat_soft_scaled).to(device)\n",
        "\n",
        "train_ds_fc = TensorDataset(train_features_soft_tensor, train_labels_soft.to(device))\n",
        "test_ds_fc = TensorDataset(test_features_soft_tensor, test_labels_soft.to(device))\n",
        "\n",
        "train_loader_fc = DataLoader(train_ds_fc, batch_size=32, shuffle=True)\n",
        "test_loader_fc = DataLoader(test_ds_fc, batch_size=32, shuffle=False)\n",
        "\n",
        "# ==============================================================\n",
        "# 6. 训练 FC 模型（软标签）\n",
        "# ==============================================================\n",
        "print(\"\\n=== 训练 FC 模型（软标签）===\")\n",
        "fc_model.train()\n",
        "EPOCHS = 50\n",
        "best_val_f1 = 0.0\n",
        "patience = 7\n",
        "no_imp = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0.0\n",
        "    for x, y in train_loader_fc:\n",
        "        optimizer.zero_grad()\n",
        "        logits = fc_model(x).squeeze(1)\n",
        "        loss = mixed_loss(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # 验证\n",
        "    fc_model.eval()\n",
        "    preds, true = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader_fc:\n",
        "            prob = torch.sigmoid(fc_model(x)).cpu().numpy()\n",
        "            preds.extend(prob.flatten())\n",
        "            true.extend(y.cpu().numpy())\n",
        "    fc_model.train()\n",
        "\n",
        "    preds_bin = (np.array(preds) > 0.5).astype(int)\n",
        "    true_bin = (np.array(true) > 0.5).astype(int)\n",
        "    val_acc = accuracy_score(true_bin, preds_bin)\n",
        "    val_f1 = f1_score(true_bin, preds_bin, average='macro')\n",
        "\n",
        "    print(f\"Epoch {epoch+1:2d} | Loss {epoch_loss/len(train_loader_fc):.4f} | ValAcc {val_acc:.4f} | ValF1 {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(fc_model.state_dict(), 'best_fc_soft.pth')\n",
        "        no_imp = 0\n",
        "    else:\n",
        "        no_imp += 1\n",
        "        if no_imp >= patience:\n",
        "            print(\"⏸ Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "fc_model.load_state_dict(torch.load('best_fc_soft.pth'))\n",
        "print(f\"✅ FC 训练完成，Best Val F1: {best_val_f1:.4f}\")\n",
        "\n",
        "# ==============================================================\n",
        "# 7. 训练 LightGBM（硬标签）\n",
        "# ==============================================================\n",
        "print(\"\\n=== 训练 LightGBM（硬标签）===\")\n",
        "\n",
        "# 转换为硬标签\n",
        "train_labels_hard_binary = (train_labels_hard.cpu().numpy() > 0.5).astype(int)\n",
        "\n",
        "lgb_train = lgb.Dataset(train_feat_hard_scaled, label=train_labels_hard_binary)\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 64,\n",
        "    'max_depth': 10,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.8,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'verbose': -1,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(\n",
        "    params,\n",
        "    lgb_train,\n",
        "    num_boost_round=1000,\n",
        "    valid_sets=[lgb_train],\n",
        "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(100)]\n",
        ")\n",
        "\n",
        "print(\"✅ LightGBM 训练完成\")\n",
        "\n",
        "# ==============================================================\n",
        "# 8. 混合集成预测\n",
        "# ==============================================================\n",
        "print(\"\\n=== 混合集成预测 ===\")\n",
        "\n",
        "# FC 预测（软标签训练）\n",
        "fc_model.eval()\n",
        "fc_probs = []\n",
        "with torch.no_grad():\n",
        "    for x, _ in test_loader_fc:\n",
        "        prob = torch.sigmoid(fc_model(x)).cpu().numpy().flatten()\n",
        "        fc_probs.extend(prob)\n",
        "fc_probs = np.array(fc_probs)\n",
        "\n",
        "# LightGBM 预测（硬标签训练）\n",
        "lgb_probs = lgb_model.predict(test_feat_hard_scaled)\n",
        "\n",
        "# 集成策略：FC权重更高（因为软标签效果更好）\n",
        "ensemble_prob = 0.6 * fc_probs + 0.4 * lgb_probs\n",
        "ensemble_pred = (ensemble_prob > 0.5).astype(int)\n",
        "\n",
        "# 真实标签（二值化）\n",
        "y_true = (test_labels_soft.cpu().numpy() > 0.5).astype(int)\n",
        "\n",
        "# ==============================================================\n",
        "# 9. 评估结果\n",
        "# ==============================================================\n",
        "def evaluate_model(name, probs):\n",
        "    preds = (probs > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_true, preds)\n",
        "    f1 = f1_score(y_true, preds, average='macro')\n",
        "    return acc, f1\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📊 最终结果对比\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fc_acc, fc_f1 = evaluate_model(\"FC (软标签)\", fc_probs)\n",
        "lgb_acc, lgb_f1 = evaluate_model(\"LightGBM (硬标签)\", lgb_probs)\n",
        "ens_acc, ens_f1 = evaluate_model(\"集成 (0.6*FC + 0.4*LGB)\", ensemble_prob)\n",
        "\n",
        "print(f\"{'模型':<25} {'Accuracy':<12} {'F1-Score'}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'FC (软标签)':<25} {fc_acc:<12.4f} {fc_f1:.4f}\")\n",
        "print(f\"{'LightGBM (硬标签)':<25} {lgb_acc:<12.4f} {lgb_f1:.4f}\")\n",
        "print(f\"{'集成 (0.6*FC + 0.4*LGB)':<25} {ens_acc:<12.4f} {ens_f1:.4f} ⭐\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 详细分类报告\n",
        "print(\"\\n📋 集成模型详细报告：\")\n",
        "print(classification_report(y_true, ensemble_pred, target_names=['Class 0', 'Class 1']))\n",
        "\n",
        "# ==============================================================\n",
        "# 10. 保存模型\n",
        "# ==============================================================\n",
        "torch.save(fc_model.state_dict(), 'fc_soft_final.pth')\n",
        "lgb_model.save_model('lgb_hard_final.txt')\n",
        "print(\"\\n💾 模型已保存：fc_soft_final.pth & lgb_hard_final.txt\")\n",
        "\n",
        "# ==============================================================\n",
        "# 11. 权重调优（可选）\n",
        "# ==============================================================\n",
        "print(\"\\n🔧 尝试不同集成权重：\")\n",
        "print(\"-\" * 60)\n",
        "for w in [0.5, 0.55, 0.6, 0.65, 0.7]:\n",
        "    ens = w * fc_probs + (1-w) * lgb_probs\n",
        "    ens_pred = (ens > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_true, ens_pred)\n",
        "    f1 = f1_score(y_true, ens_pred, average='macro')\n",
        "    print(f\"权重 {w:.2f}*FC + {1-w:.2f}*LGB  →  Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1G1WZfukOeh",
        "outputId": "4e89a71b-e0a0-48a5-d180-c1f609adcf9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Train/Val/Test: 3235/404/405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 提取软标签特征（用于FC）===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting:  31%|███       | 63/203 [00:21<00:42,  3.31it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Extracting: 100%|██████████| 203/203 [01:11<00:00,  2.83it/s]\n",
            "Extracting: 100%|██████████| 26/26 [00:08<00:00,  2.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 提取硬标签特征（用于LightGBM）===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting: 100%|██████████| 203/203 [01:11<00:00,  2.85it/s]\n",
            "Extracting: 100%|██████████| 26/26 [00:08<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 特征标准化完成\n",
            "\n",
            "=== 训练 FC 模型（软标签）===\n",
            "Epoch  1 | Loss 0.5108 | ValAcc 0.5728 | ValF1 0.5682\n",
            "Epoch  2 | Loss 0.4933 | ValAcc 0.6370 | ValF1 0.6245\n",
            "Epoch  3 | Loss 0.4809 | ValAcc 0.6395 | ValF1 0.6176\n",
            "Epoch  4 | Loss 0.4723 | ValAcc 0.6519 | ValF1 0.6338\n",
            "Epoch  5 | Loss 0.4633 | ValAcc 0.6321 | ValF1 0.6112\n",
            "Epoch  6 | Loss 0.4565 | ValAcc 0.6272 | ValF1 0.6120\n",
            "Epoch  7 | Loss 0.4497 | ValAcc 0.6296 | ValF1 0.6081\n",
            "Epoch  8 | Loss 0.4463 | ValAcc 0.6667 | ValF1 0.6468\n",
            "Epoch  9 | Loss 0.4400 | ValAcc 0.6420 | ValF1 0.6207\n",
            "Epoch 10 | Loss 0.4351 | ValAcc 0.6272 | ValF1 0.6157\n",
            "Epoch 11 | Loss 0.4303 | ValAcc 0.6395 | ValF1 0.6176\n",
            "Epoch 12 | Loss 0.4259 | ValAcc 0.6395 | ValF1 0.6252\n",
            "Epoch 13 | Loss 0.4193 | ValAcc 0.6173 | ValF1 0.6081\n",
            "Epoch 14 | Loss 0.4150 | ValAcc 0.6395 | ValF1 0.6166\n",
            "Epoch 15 | Loss 0.4147 | ValAcc 0.6494 | ValF1 0.6186\n",
            "⏸ Early stopping triggered\n",
            "✅ FC 训练完成，Best Val F1: 0.6468\n",
            "\n",
            "=== 训练 LightGBM（硬标签）===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/lightgbm/callback.py:347: UserWarning: Only training set found, disabling early stopping.\n",
            "  _log_warning(\"Only training set found, disabling early stopping.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100]\ttraining's binary_logloss: 0.131511\n",
            "[200]\ttraining's binary_logloss: 0.0333385\n",
            "[300]\ttraining's binary_logloss: 0.010415\n",
            "[400]\ttraining's binary_logloss: 0.00441888\n",
            "[500]\ttraining's binary_logloss: 0.00236646\n",
            "[600]\ttraining's binary_logloss: 0.00181958\n",
            "[700]\ttraining's binary_logloss: 0.00158907\n",
            "[800]\ttraining's binary_logloss: 0.00150369\n",
            "[900]\ttraining's binary_logloss: 0.00146902\n",
            "[1000]\ttraining's binary_logloss: 0.00147069\n",
            "✅ LightGBM 训练完成\n",
            "\n",
            "=== 混合集成预测 ===\n",
            "\n",
            "============================================================\n",
            "📊 最终结果对比\n",
            "============================================================\n",
            "模型                        Accuracy     F1-Score\n",
            "------------------------------------------------------------\n",
            "FC (软标签)                  0.6667       0.6468\n",
            "LightGBM (硬标签)            0.5432       0.4706\n",
            "集成 (0.6*FC + 0.4*LGB)     0.6247       0.5778 ⭐\n",
            "============================================================\n",
            "\n",
            "📋 集成模型详细报告：\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.73      0.71      0.72       275\n",
            "     Class 1       0.42      0.45      0.44       130\n",
            "\n",
            "    accuracy                           0.62       405\n",
            "   macro avg       0.58      0.58      0.58       405\n",
            "weighted avg       0.63      0.62      0.63       405\n",
            "\n",
            "\n",
            "💾 模型已保存：fc_soft_final.pth & lgb_hard_final.txt\n",
            "\n",
            "🔧 尝试不同集成权重：\n",
            "------------------------------------------------------------\n",
            "权重 0.50*FC + 0.50*LGB  →  Acc: 0.5827, F1: 0.5184\n",
            "权重 0.55*FC + 0.45*LGB  →  Acc: 0.6000, F1: 0.5430\n",
            "权重 0.60*FC + 0.40*LGB  →  Acc: 0.6247, F1: 0.5778\n",
            "权重 0.65*FC + 0.35*LGB  →  Acc: 0.6346, F1: 0.5947\n",
            "权重 0.70*FC + 0.30*LGB  →  Acc: 0.6444, F1: 0.6070\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}